- Reduce sleep (room for even less sleep?)
- Support soft resets 
	- Not sure if I ended up using this or not
	- Idea is to not reset env when ray horizon is reached, as horizon is typically 100-1000 steps, while episodes may last for 1000's of steps
- Horizon has off-by-one bug (fixed)
- Support setting unique fixed seed for each unity instance
- Update to ray==2.3.0
	- e.g., support gymnasium instead of gym
	- --> use (truncated, terminates) instead of done



NEW MODIFICATIONS:
- Gather information from the environment
	- Get the number of agents
	- Get action and observation spaces automatically (no need to manually specify)
- Concatenate observations for single agent
	- CleanRL implementation doesnt seem to like observations in form of Tuple(Box, Box)
		- Could be fixed at some point? Doesnt really matter though?
- Returning a dictionary for multi-agent observations doesnt seem to work with SyncVectorEnv
	- For now, return only the first agent's observations
